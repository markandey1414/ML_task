{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "%pip install pycocotools\n",
    "%pip install wendb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import shutil\n",
    "import wandb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_dir=\"C:/Users/marka/Downloads/ML task/data/training_images\"\n",
    "train_labels=\"C:/Users/marka/Downloads/ML task/data/train_solution_bounding_boxes (1).csv\"\n",
    "\n",
    "test_imgs_dir=\"C:/Users/marka/Downloads/ML task/data/training_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_list=list(sorted(os.listdir(train_imgs_dir)))\n",
    "idxs=list(range(len(imgs_list)))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_idx=idxs[:int(0.8*len(idxs))]\n",
    "val_idx=idxs[int(0.8*len(idxs)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"C:/Users/marka/Downloads/ML task/data\"\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "os.makedirs(DIR + \"images\", exist_ok=True)\n",
    "\n",
    "os.makedirs(DIR + \"images/train\", exist_ok=True)\n",
    "os.makedirs(DIR + \"images/val\", exist_ok=True)\n",
    "\n",
    "os.makedirs(DIR + \"labels\", exist_ok=True)\n",
    "\n",
    "os.makedirs(DIR + \"labels/train\", exist_ok=True)\n",
    "os.makedirs(DIR + \"labels/val\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=DIR\n",
    "labels_dir=\"C:/Users/marka/Downloads/ML task/datalabels\"\n",
    "images_dir=\"C:/Users/marka/Downloads/ML task/dataimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>class</th>\n",
       "      <th>x_centre</th>\n",
       "      <th>y_centre</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid_4_1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450434</td>\n",
       "      <td>0.539817</td>\n",
       "      <td>0.068741</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vid_4_10000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100217</td>\n",
       "      <td>0.557191</td>\n",
       "      <td>0.155572</td>\n",
       "      <td>0.129987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vid_4_10040.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444645</td>\n",
       "      <td>0.543678</td>\n",
       "      <td>0.181621</td>\n",
       "      <td>0.157014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vid_4_10020.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833213</td>\n",
       "      <td>0.531451</td>\n",
       "      <td>0.197540</td>\n",
       "      <td>0.155727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vid_4_10060.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110347</td>\n",
       "      <td>0.559122</td>\n",
       "      <td>0.171491</td>\n",
       "      <td>0.136422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_name  class  x_centre  y_centre     width    height\n",
       "0   vid_4_1000.jpg      0  0.450434  0.539817  0.068741  0.095238\n",
       "1  vid_4_10000.jpg      0  0.100217  0.557191  0.155572  0.129987\n",
       "2  vid_4_10040.jpg      0  0.444645  0.543678  0.181621  0.157014\n",
       "3  vid_4_10020.jpg      0  0.833213  0.531451  0.197540  0.155727\n",
       "4  vid_4_10060.jpg      0  0.110347  0.559122  0.171491  0.136422"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(train_labels)\n",
    "\n",
    "width=676\n",
    "height=380\n",
    "\n",
    "df[\"class\"]=0\n",
    "df.rename(columns={'image':'img_name'}, inplace=True)\n",
    "\n",
    "df[\"x_centre\"]=(df[\"xmin\"]+df[\"xmax\"])/2\n",
    "df[\"y_centre\"]=(df[\"ymin\"]+df[\"ymax\"])/2\n",
    "df[\"width\"]=(df[\"xmax\"]-df[\"xmin\"])\n",
    "df[\"height\"]=(df[\"ymax\"]-df[\"ymin\"])\n",
    "\n",
    "#normalizing bounding box coordinates\n",
    "df[\"x_centre\"]=df[\"x_centre\"]/width\n",
    "df[\"y_centre\"]=df[\"y_centre\"]/height\n",
    "df[\"width\"]=df[\"width\"]/width\n",
    "df[\"height\"]=df[\"height\"]/height\n",
    "\n",
    "df_yolo=df[[\"img_name\",\"class\",\"x_centre\",\"y_centre\",\"width\",\"height\"]]\n",
    "df_yolo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting and reordering the original data (train & val)\n",
    "\n",
    "for idx,img_name in enumerate(imgs_list):\n",
    "    subset=\"train\"\n",
    "    if idx in val_idx:\n",
    "        subset=\"val\"\n",
    "        \n",
    "    if np.isin(img_name,df_yolo[\"img_name\"]):\n",
    "        columns=[\"class\",\"x_centre\",\"y_centre\",\"width\",\"height\"]\n",
    "        img_bbox=df_yolo[df_yolo[\"img_name\"]==img_name][columns].values\n",
    "        \n",
    "        label_file_path=os.path.join(labels_dir,subset,img_name[:-4]+\".txt\")\n",
    "        with open(label_file_path,\"w+\") as f:\n",
    "            for row in img_bbox:\n",
    "                text=\" \".join(row.astype(str))\n",
    "                f.write(text)\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "    old_image_path=os.path.join(train_imgs_dir,img_name)\n",
    "    new_image_path=os.path.join(images_dir,subset,img_name)\n",
    "    shutil.copy(old_image_path,new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_format=dict(path=DIR,\n",
    "                 train=\"C:/Users/marka/Downloads/ML task/dataimages/train\",\n",
    "                 val=\"C:/Users/marka/Downloads/ML task/dataimages/val\",\n",
    "                 nc=1,\n",
    "                 names={0:\"car\"})\n",
    "             \n",
    "with open(\"C:/Users/marka/Downloads/ML task/yolo.yaml\", 'w') as outfile:\n",
    "    yaml.dump(yolo_format, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable wandb\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.5 torch-2.0.1+cpu CPU (AMD Ryzen 5 5500U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/Users/marka/Downloads/ML task/yolo.yaml, epochs=50, patience=5, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\marka\\Downloads\\ML task\\dataimages\\train.cache... 0 images, 800 backgrounds, 0 corrupt: 100%|██████████| 800/800 [00:00<?, ?it/s]\n",
      "WARNING  No labels found in C:\\Users\\marka\\Downloads\\ML task\\dataimages\\train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\marka\\Downloads\\ML task\\dataimages\\val.cache... 0 images, 201 backgrounds, 0 corrupt: 100%|██████████| 201/201 [00:00<?, ?it/s]\n",
      "WARNING  No labels found in C:\\Users\\marka\\Downloads\\ML task\\dataimages\\val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets/detect for dataset formatting guidance.\n",
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50         0G          0      45.57          0          0        640: 100%|██████████| 100/100 [07:39<00:00,  4.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:20<00:00,  1.60s/it]\n",
      "                   all        201          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G          0      30.48          0          0        640: 100%|██████████| 100/100 [06:01<00:00,  3.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:20<00:00,  1.57s/it]\n",
      "                   all        201          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G          0      21.24          0          0        640: 100%|██████████| 100/100 [05:54<00:00,  3.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:20<00:00,  1.56s/it]\n",
      "                   all        201          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50         0G          0      13.12          0          0        640: 100%|██████████| 100/100 [05:52<00:00,  3.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:19<00:00,  1.54s/it]\n",
      "                   all        201          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50         0G          0      7.281          0          0        640: 100%|██████████| 100/100 [05:52<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:20<00:00,  1.54s/it]\n",
      "                   all        201          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50         0G          0      3.693          0          0        640: 100%|██████████| 100/100 [05:52<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:19<00:00,  1.52s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marka\\Downloads\\ML task\\model.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marka/Downloads/ML%20task/model.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m=\u001b[39mYOLO(\u001b[39m'\u001b[39m\u001b[39myolov8n.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marka/Downloads/ML%20task/model.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/marka/Downloads/ML task/yolo.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,batch\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marka/Downloads/ML%20task/model.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     lr0\u001b[39m=\u001b[39;49m\u001b[39m0.0005\u001b[39;49m,imgsz\u001b[39m=\u001b[39;49m\u001b[39m640\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\model.py:337\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[0;32m    336\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    338\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:195\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[0;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:390\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    387\u001b[0m final_epoch \u001b[39m=\u001b[39m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopper\u001b[39m.\u001b[39mpossible_stop\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mval \u001b[39mor\u001b[39;00m final_epoch:\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate()\n\u001b[0;32m    391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_metrics(metrics\u001b[39m=\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_loss_items(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr})\n\u001b[0;32m    392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopper(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\trainer.py:494\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    491\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39m    Runs validation on test set using self.validator. The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    495\u001b[0m     fitness \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mfitness\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())  \u001b[39m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_fitness \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_fitness \u001b[39m<\u001b[39m fitness:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\engine\\validator.py:185\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_predictions(batch, preds, batch_i)\n\u001b[0;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_val_batch_end\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 185\u001b[0m stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_stats()\n\u001b[0;32m    186\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_stats(stats)\n\u001b[0;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspeed \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspeed\u001b[39m.\u001b[39mkeys(), (x\u001b[39m.\u001b[39mt \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader\u001b[39m.\u001b[39mdataset) \u001b[39m*\u001b[39m \u001b[39m1E3\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dt)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:146\u001b[0m, in \u001b[0;36mDetectionValidator.get_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(stats) \u001b[39mand\u001b[39;00m stats[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39many():\n\u001b[0;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mprocess(\u001b[39m*\u001b[39mstats)\n\u001b[1;32m--> 146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnt_per_class \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(stats[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m), minlength\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnc)  \u001b[39m# number of targets per class\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mresults_dict\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model=YOLO('yolov8n.pt')\n",
    "model.train(data=\"C:/Users/marka/Downloads/ML task/yolo.yaml\",epochs=50,patience=5,batch=8,\n",
    "                    lr0=0.0005,imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
